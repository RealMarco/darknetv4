[net]
# Testing
# batch=1
# subdivisions=1
# Training
batch=32
subdivisions=8
width=1024
height=768
channels=3
momentum=0.9
decay=0.0005
angle=180
saturation = 1.4
exposure = 1.4
hue=.2

learning_rate=0.001
burn_in=2000   #1000
max_batches = 14000
policy=steps
steps=4000,5200,6000,7800 ,10000 ,11000,12000,13000 #,17000
scales=.2,.5,.5,.2  ,2,.5,.5,.2 #,.2

[convolutional]
batch_normalize=1
filters=16
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=1

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

###########

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=24
activation=linear



[yolo]
mask = 3,4,5
anchors = 131,186, 144,100, 274,166, 301,281, 501,341, 657,525
classes=3
num=6
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1

[route]
layers = -4

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 8

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=24
activation=linear

[yolo]
mask = 0,1,2
anchors = 131,186, 144,100, 274,166, 301,281, 501,341, 657,525
classes=3
num=6
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
